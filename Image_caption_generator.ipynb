{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "1. data collection\n",
    "2. Understanding the data\n",
    "3. Data cleaning\n",
    "4. Loading the training set\n",
    "5. Data preprocessing - images\n",
    "6. Data preprocessing - Captions\n",
    "7. Data preparation using Generator Function\n",
    "8. Word Embeddings\n",
    "9. Model Architecture\n",
    "10. Inference\n",
    "11. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import json\n",
    "from time import time\n",
    "import pickle\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input,Dense,Dropout,Embedding, LSTM\n",
    "from keras.layers.merge import add\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read text caption\n",
    "\n",
    "def readTextFile(path):\n",
    "    with open(path) as f:\n",
    "        captions = f.read() #readline to read each line\n",
    "    return captions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = readTextFile(\"flickr_dataset/Flickr8k_text/Flickr8k.token.txt\")\n",
    "captions = captions.split(\"\\n\")[:-1]\n",
    "#len(captions.split(\"\\n\"))  --> 40461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first, second = captions[0].split(\"\\t\")\n",
    "print(first.split(\".\")[0])\n",
    "print(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(captions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = {}\n",
    "\n",
    "for i in range(0,40460):\n",
    "    first, second = captions[i].split(\"\\t\")\n",
    "    img_name = first.split(\".\")[0]\n",
    "    \n",
    "    #if the image id is already present or not\n",
    "    if descriptions.get(img_name) is None:\n",
    "        descriptions[img_name] = []\n",
    "        \n",
    "    descriptions[img_name].append(second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = \"flickr_dataset/Flicker8k_Dataset/\"\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(IMG_PATH+\"1000268201_693b08cb0e.jpg\")\n",
    "cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(\"[^a-z]\",\" \", sentence)\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    sentence = [s for s in sentence if len(s)>1]\n",
    "    sentence = \" \".join(sentence)\n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text(\"A cat is sitting over the house number 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean all captions\n",
    "for key, caption_list in descriptions.items():\n",
    "    for i in range(len(caption_list)):\n",
    "        caption_list[i] = clean_text(caption_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the data to text file\n",
    "with open(\"descriptions_1.txt\",\"w\") as f:\n",
    "    f.write(str(descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary\n",
    "(set of all unique words model can predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = None\n",
    "with open(\"descriptions_1.txt\",\"r\") as f:\n",
    "    descriptions= f.read()\n",
    "    \n",
    "json_acceptable_string = descriptions.replace(\"'\",\"\\\"\")\n",
    "descriptions = json.loads(json_acceptable_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(descriptions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "vocab = set()\n",
    "for key in descriptions.keys():\n",
    "    [vocab.update(sentence.split()) for sentence in descriptions[key]]\n",
    "    \n",
    "print(\"Vocab Size : %d\"% len(vocab))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words = []\n",
    "\n",
    "for key in descriptions.keys():\n",
    "    [total_words.append(i) for des in descriptions[key] for i in des.split()]\n",
    "    \n",
    "print(\"Total words %d\"%len(total_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(total_words)\n",
    "freq_cnt = dict(counter)\n",
    "print(len(freq_cnt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dictionary according to the freq count\n",
    "sorted_freq_cnt = sorted(freq_cnt.items(), reverse=True, key= lambda x:x[1])\n",
    "\n",
    "#Filter\n",
    "threshold = 10\n",
    "sorted_freq_cnt = [x for x in sorted_freq_cnt if x[1]>threshold]\n",
    "total_words = [x[0] for x in sorted_freq_cnt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted_freq_cnt\n",
    "'''\n",
    "[('in', 18987),\n",
    " ('the', 18420),\n",
    " ('on', 10746),\n",
    " ('is', 9345),\n",
    " ('and', 8863),\n",
    " ('dog', 8138),\n",
    " ('with', 7765),\n",
    " ('man', 7275),.............]\n",
    " '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_data = readTextFile(\"flickr_dataset/Flickr8k_text/Flickr_8k.trainImages.txt\")\n",
    "test_file_data = readTextFile(\"flickr_dataset/Flickr8k_text/Flickr_8k.testImages.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_file_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [row.split(\".\")[0] for row in train_file_data.split(\"\\n\")[:-1]]\n",
    "test = [row.split(\".\")[0] for row in test_file_data.split(\"\\n\")[:-1]]\n",
    "\n",
    "print(train[:5])\n",
    "# print(test[:-10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions= {}\n",
    "\n",
    "for img_id in train:\n",
    "    train_descriptions[img_id] = []\n",
    "    for cap in descriptions[img_id]:\n",
    "        cap_to_append =\"startseq \"+cap+\" endseq\"\n",
    "        train_descriptions[img_id].append(cap_to_append)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_descriptions[\"1000268201_693b08cb0e\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "images --> Features\n",
    "Text ----> Features\n",
    "\n",
    "## Step 1 Image Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights=\"imagenet\", input_shape=(224,224,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet --> extract features\n",
    "model.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[-2].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(model.input, model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    img = image.load_img(img, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    # Normalisation\n",
    "    img = preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_img(IMG_PATH+\"1000268201_693b08cb0e.jpg\")\n",
    "plt.imshow(img[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "# print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_img(img):\n",
    "    img = preprocess_img(img)\n",
    "    feature_vector = model_new.predict(img)\n",
    "    feature_vector = feature_vector.reshape((-1,))\n",
    "    #print(feature_vector.shape)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_img(IMG_PATH+\"1000268201_693b08cb0e.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_train = {}\n",
    "#image_id ---> feature_vector extracted from Resnet Image\n",
    "for ix, img_ig in enumerate(train):\n",
    "    img_path = IMG_PATH+\"/\"+img_id+\".jpg\"\n",
    "    encoding_train[img_id] = encode_img(img_path)\n",
    "    \n",
    "    if ix%100==0 :\n",
    "        print(\"Encoding in Progress Time step %d \"%ix)\n",
    "end_t = time()\n",
    "print(\"Total time taken :\", end_t - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store every thing to the disk\n",
    "with open(\"encoded_train_features.pk1\",\"wb\") as f:\n",
    "    pickle.dump(encoding_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "encoding_test = {}\n",
    "#image_id ---> feature_vector extracted from Resnet Image\n",
    "for ix, img_ig in enumerate(test):\n",
    "    img_path = IMG_PATH+\"/\"+img_id+\".jpg\"\n",
    "    encoding_test[img_id] = encode_img(img_path)\n",
    "    \n",
    "    if ix%100==0 :\n",
    "        print(\"Test Encoding in Progress Time step %d \"%ix)\n",
    "end_t = time()\n",
    "print(\"Total time taken(test) :\", end_t - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store every thing to the disk\n",
    "with open(\"encoded_test_features.pk1\",\"wb\") as f:\n",
    "    pickle.dump(encoding_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing for Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "len(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for i,word in enumerate(total_words):\n",
    "    word_to_idx[word] = i+1\n",
    "    idx_to_word[i+1] = word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_to_idx[\"dog\"])\n",
    "print(idx_to_word[1])\n",
    "print(len(idx_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_word[1846] = 'startseq'\n",
    "word_to_idx['startseq'] = 1846\n",
    "\n",
    "idx_to_word[1847] = 'endseq'\n",
    "word_to_idx['endseq'] = 1847\n",
    "\n",
    "vocab_size = len(word_to_idx)+1\n",
    "print(\"Vocab Size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for key in train_descriptions.keys():\n",
    "    for cap in train_descriptions[key]:\n",
    "        max_len = max(max_len, len(cap.split()))\n",
    "        \n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def data_generator(train_descriptions, encoding_train,word_to_idx, max_len, batch_size):\n",
    "        X1,X2, y = [],[],[]\n",
    "        \n",
    "        n=0\n",
    "        while True:\n",
    "            for key, desc_list in train_descriptions.items():\n",
    "                n+=1\n",
    "                \n",
    "                photo = encoding_train[key+\".jpg\"]\n",
    "                for desc in desc_list:\n",
    "                    seq = [word_to_idx[word] for word in desc.split() if word in word_to_idx]\n",
    "                    for i in range(1, len(seq)):\n",
    "                        xi = seq[0:i]\n",
    "                        yi = seq[i]\n",
    "                        \n",
    "                        # 0 denote padding word\n",
    "                        xi = pad_sequence([xi],maxlen = maxlen, value = 0, padding = 'post')\n",
    "                        yi = to_categorical([yi], num_classes = vocab_size)[0]\n",
    "                        \n",
    "                        X1.append(photo)\n",
    "                        X2.append(xi)\n",
    "                        y.append(yi)\n",
    "                        \n",
    "                    if n == batch_size:\n",
    "                        yield [[np.array(X1), np.array(X2)],np.array(y)]\n",
    "                        \n",
    "                        X1,X2,y = [],[],[]\n",
    "                        n=0\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./saved/glove.6B.50d.txt\",encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    \n",
    "    word = values[0]\n",
    "    word_embedding = np.array(values[1:], dtype='float')\n",
    "    embedding_index[word] = word_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_index['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_matrix():\n",
    "    emb_dim = 50\n",
    "    matrix = np.zeros((vocab_size, emb_dim))\n",
    "    for word,idx in word_to_idx.items():\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        \n",
    "        if embedding_vector is not None:\n",
    "            matrix[idx] = embedding_vector\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(word_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = get_embedded_matrix()\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix[1847]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img_features = Input(shape=(2048,))\n",
    "inp_img1 = Dropout(0.3)(input_img_features)\n",
    "inp_img2 = Dense(256, activation='relu')(inp_img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captions as Input\n",
    "input_captions = Input(shape=(max_len,))\n",
    "inp_cap1 = Embedding(input_dim = vocab_size, output_dim = 50, mask_zero = True)(input_captions)\n",
    "inp_cap2 = Dropout(0.3)(inp_cap1)\n",
    "inp_cap3 = LSTM(256)(inp_cap2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder1 = add([inp_img2, inp_cap3])\n",
    "decoder2 = Dense(256, activation ='relu')(decoder1)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\n",
    "#Combined Model\n",
    "model = Model(inputs = [input_img_features,input_captions], outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].set_weights([embedding_matrix])\n",
    "model.layers[2].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorcal_crossentropy',optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Of Model\n",
    "epochs = 20\n",
    "batch_size  = 3\n",
    "steps = len(train_descriptions)//batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " for i in range(epochs):\n",
    "        generator= data_generator(train_descriptions, encoding_train, word_to_idx, max_len, batch_size)\n",
    "        model.fit_generator(generator, epochs = 1,steps_per_epoch = steps, verbose =1 )\n",
    "        model.save('./model_weights/model_'+ str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_caption(photo):\n",
    "    \n",
    "    in_text = \"startseq\"\n",
    "    for i in range(max_len):\n",
    "        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n",
    "        sequence = pad_sequences([sequence], maxlen = max_len, padding='post')\n",
    "        \n",
    "        ypred = model.predict([photo, sequence])\n",
    "        ypred = ypred.argmax() #word with max prob always - Greedy Sampling\n",
    "        word = idx_to_word[ypred]\n",
    "        in_text = idx_to_word[ypred]\n",
    "        in_text = ''+word\n",
    "        \n",
    "        if word == 'endseq':\n",
    "            break\n",
    "            \n",
    "    final_caption = in_text.split()[1:-1]\n",
    "    final_caption = ' '.join(final_caption)\n",
    "    \n",
    "    return final_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
